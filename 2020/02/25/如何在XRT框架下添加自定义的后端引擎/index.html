<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>如何在XRT框架下添加自定义的后端引擎 › Don&#39;t Respond</title>
  <meta name="author" content="Dou Jiang">
  
  <meta name="description" content="XRT为不同的后端引擎提供了统一的上层功能和接口抽象，这些功能和接口包括：

统一的DAG计算图表示
统一的子图表达、切分和折叠过程
统一的JIT子图编译接口和缓存机制
统一的Executable Launch接口

得益于上层统一的抽象和模块化的设计，后端引擎只需要处理一些差异化的接口，并且这些差异化通常只体现在子图的编译和executable
launch接口的具体实现上。">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="如何在XRT框架下添加自定义的后端引擎"/>
  <meta property="og:site_name" content="Don&#39;t Respond"/>

  
    <meta property="og:image" content=""/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Don&#39;t Respond" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  <header id="header"><div class="meta inner">
  <h1><a href="/">Don&#39;t Respond</a></h1>
  <h2><a href="/"></a></h2>
  <nav id="main-nav">
    <ul>
      
      <li><a href="/about">About</a></li>
      
      <li><a href="/archives">Archives</a></li>
      
      <li><a href="/atom.xml">RSS</a></li>
      
    </ul>
    <div class="clearfix"></div>
  </nav>
</div>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  <div class="post-content">
    <header>
      
  
    <h1 class="title">如何在XRT框架下添加自定义的后端引擎</h1>
  

      
        <time datetime="2020-02-25T08:06:18.000Z">2020-02-25</time>
      
    </header>
    <div class="entry">
      
        <p>XRT为不同的后端引擎提供了统一的上层功能和接口抽象，这些功能和接口包括：</p>
<ul>
<li>统一的DAG计算图表示</li>
<li>统一的子图表达、切分和折叠过程</li>
<li>统一的JIT子图编译接口和缓存机制</li>
<li>统一的Executable Launch接口</li>
</ul>
<p>得益于上层统一的抽象和模块化的设计，后端引擎只需要处理一些差异化的接口，并且这些差异化通常只体现在子图的编译和executable
launch接口的具体实现上。</p>
<span id="more"></span>
<p>我们把XRT的每个子图都看成是一个function，function包含输入和输出参数，以及对应的函数体（DAG表示的计算图），比如下面表示的是只包含一个relu节点的XRT子图，其中node表示计算节点，input和output分别表示子图的输入和输出。</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">function &#123;</span><br><span class="line">  input &#123;</span><br><span class="line">    name: &quot;_xrt_entry_0&quot;</span><br><span class="line">    value: &quot;_MyGraph_0_input.0.0_2/out&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  output &#123;</span><br><span class="line">    name: &quot;_xrt_return_0&quot;</span><br><span class="line">    value: &quot;relu-0/y_0&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  node &#123;</span><br><span class="line">    name: &quot;relu-0&quot;</span><br><span class="line">    device_tag: &quot;cuda&quot;</span><br><span class="line">    user_conf &#123;</span><br><span class="line">      op_type_name: &quot;relu&quot;</span><br><span class="line">      input &#123;</span><br><span class="line">        key: &quot;x&quot;</span><br><span class="line">        value &#123;</span><br><span class="line">          s: &quot;_MyGraph_0_input.0.0_2/out&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      output &#123;</span><br><span class="line">        key: &quot;y&quot;</span><br><span class="line">        value &#123;</span><br><span class="line">          s: &quot;relu-0/y_0&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在runtime阶段function首先需要被编译成executable，执行function实际上就是feed对应的输入参数去launch这个编译好的executable，同时得到执行的结果，即function的返回值。</p>
<p>在XRT框架下每个后端引擎都有一个与之相对应的executable（比如XLA的XlaExecutable和TensorRT的TrtExecutable），和将function编译成对应executable的compiler（比如XLA的XlaGraphCompiler和TensorRT的TrtGraphCompiler），因此添加一个新的后端引擎，通常只需要添加一个对应的executable和compiler。下面以添加一个自定义的后端引擎Toy为例，详细介绍在XRT框架下支持新的后端引擎的具体过程。</p>
<p>首先在xrt.proto文件中XrtEngine下增加一个Toy引擎字段。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">XrtEngine</span> &#123;</span><br><span class="line">  DEFAULT = <span class="number">1</span>;</span><br><span class="line">  XLA = <span class="number">2</span>;</span><br><span class="line">  TENSORRT = <span class="number">3</span>;</span><br><span class="line">  TVM = <span class="number">4</span>;</span><br><span class="line">  TOY = <span class="number">5</span>;  <span class="comment">// For Toy engine</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果Toy引擎针对的硬件不在XrtDevice中，则需要在XrtDevice中增加对应的设备字段。这里我们假设自定义的Toy引擎只支持GPU_CUDA，因此就不需要修改XrtDevice了。</p>
<p>接下来，与XLA和TensorRT一样，我们在<code>oneflow_xrt/compiler</code>目录下创建一个toy目录，其余所有与Toy引擎相关的代码都将放在该目录下。</p>
<h2 id="toy-executable">Toy Executable</h2>
<p>在增加任何一个后端引擎之前，我们都需要仔细考虑该后端引擎所需的最小执行环境，一个最简单的执行环境包括输入输出、中间结果以及执行具体计算逻辑的硬件代码，这个代码可以是通过codegen自动生成的，也可以是手工实现的。</p>
<p>接下来我们给自定义的Toy引擎增加一个对应的ToyExecutable。在<code>oneflow_xrt/compiler/toy</code>目录下，我们创建文件toy_executable.h和toy_executable.cpp。</p>
<p>toy_executable.h中定义ToyExecutable，ToyExecutable必须继承自Executable，并实现Run接口。为了尽可能简单，ToyExecutable只包含输出outputs、中间结果tmp_buffers和编排好的函数调用列表func_codes，以及每个函数的输入输出参数对应的buffer序号func_args_。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> ONEFLOW_XRT_COMPILER_TOY_TOY_EXECUTABLE_H_</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;oneflow_xrt/compiler/executable.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;oneflow_xrt/compiler/parameter.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;functional&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> oneflow &#123;</span><br><span class="line"><span class="keyword">namespace</span> xrt &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> std::function&lt;<span class="type">void</span>(<span class="type">const</span> std::vector&lt;Parameter&gt; &amp;,</span><br><span class="line">                           <span class="type">const</span> std::vector&lt;Parameter&gt; &amp;)&gt; FuncCode;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">FuncArgumentIndices</span> &#123;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>&gt; inputs;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>&gt; outputs;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ToyExecutable</span> : <span class="keyword">public</span> Executable &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">ToyExecutable</span>(<span class="type">const</span> std::string &amp;name, <span class="type">const</span> <span class="type">int</span> num_inputs,</span><br><span class="line">                 <span class="type">const</span> std::vector&lt;Parameter&gt; &amp;outputs,</span><br><span class="line">                 <span class="type">const</span> std::vector&lt;Parameter&gt; &amp;temp_buffers,</span><br><span class="line">                 <span class="type">const</span> std::vector&lt;FuncCode&gt; &amp;func_codes,</span><br><span class="line">                 <span class="type">const</span> std::vector&lt;FuncArgumentIndices&gt; &amp;func_args);</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">Run</span><span class="params">(<span class="type">const</span> std::vector&lt;Parameter&gt; &amp;inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">           <span class="type">const</span> ExecutableRunOptions &amp;run_options,</span></span></span><br><span class="line"><span class="params"><span class="function">           <span class="type">bool</span> block_until_done = <span class="literal">true</span>)</span> <span class="keyword">override</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">int</span> num_inputs_;</span><br><span class="line">  std::vector&lt;Parameter&gt; outputs_;</span><br><span class="line">  std::vector&lt;Parameter&gt; temp_buffers_;</span><br><span class="line">  std::vector&lt;FuncCode&gt; func_codes_;</span><br><span class="line">  std::vector&lt;FuncArgumentIndices&gt; func_args_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace xrt</span></span><br><span class="line">&#125;  <span class="comment">// namespace oneflow</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">// ONEFLOW_XRT_COMPILER_TOY_TOY_EXECUTABLE_H_</span></span></span><br></pre></td></tr></table></figure>
<p>在toy_executable.cpp中实现Run方法，这里我们只是简单的顺序执行编排好的函数func_codes。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;oneflow_xrt/compiler/toy/toy_executable.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> oneflow &#123;</span><br><span class="line"><span class="keyword">namespace</span> xrt &#123;</span><br><span class="line"></span><br><span class="line">ToyExecutable::<span class="built_in">ToyExecutable</span>(<span class="type">const</span> std::string &amp;name, <span class="type">const</span> <span class="type">int</span> num_inputs,</span><br><span class="line">                               <span class="type">const</span> std::vector&lt;Parameter&gt; &amp;outputs,</span><br><span class="line">                               <span class="type">const</span> std::vector&lt;Parameter&gt; &amp;temp_buffers,</span><br><span class="line">                               <span class="type">const</span> std::vector&lt;FuncCode&gt; &amp;func_codes,</span><br><span class="line">                               <span class="type">const</span> std::vector&lt;FuncArgumentIndices&gt; &amp;func_args)</span><br><span class="line">    : <span class="built_in">Executable</span>(name, XrtEngine::TOY),</span><br><span class="line">      <span class="built_in">num_inputs_</span>(num_inputs),</span><br><span class="line">      <span class="built_in">outputs_</span>(outputs),</span><br><span class="line">      <span class="built_in">temp_buffers_</span>(temp_buffers),</span><br><span class="line">      <span class="built_in">func_codes_</span>(func_codes),</span><br><span class="line">      <span class="built_in">func_args_</span>(func_args) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">ToyExecutable::Run</span><span class="params">(<span class="type">const</span> std::vector&lt;Parameter&gt; &amp;inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">                         <span class="type">const</span> ExecutableRunOptions &amp;run_options,</span></span></span><br><span class="line"><span class="params"><span class="function">                         <span class="type">bool</span> block_until_done)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> PullArgs = [&amp;](<span class="type">const</span> std::vector&lt;<span class="type">int</span>&gt; &amp;indices) &#123;</span><br><span class="line">    std::vector&lt;Parameter&gt; args;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> idx : indices) &#123;</span><br><span class="line">      <span class="keyword">if</span> (idx &lt; num_inputs_) &#123;</span><br><span class="line">        args.<span class="built_in">push_back</span>(inputs[idx]);</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (idx &lt; num_inputs_ + outputs_.<span class="built_in">size</span>()) &#123;</span><br><span class="line">        args.<span class="built_in">push_back</span>(outputs_[idx - num_inputs_]);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        idx -= (num_inputs_ + outputs_.<span class="built_in">size</span>());</span><br><span class="line">        <span class="built_in">CHECK_GE</span>(idx, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">CHECK_LT</span>(idx, temp_buffers_.<span class="built_in">size</span>());</span><br><span class="line">        args.<span class="built_in">push_back</span>(temp_buffers_[idx]);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">move</span>(args);</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">CHECK_EQ</span>(inputs.<span class="built_in">size</span>(), num_inputs_);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; func_codes_.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">    <span class="keyword">auto</span> in_args = <span class="built_in">PullArgs</span>(func_args_[i].inputs);</span><br><span class="line">    <span class="keyword">auto</span> out_args = <span class="built_in">PullArgs</span>(func_args_[i].outputs);</span><br><span class="line">    func_codes_[i](in_args, out_args);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Synchronize stream if block_until_done</span></span><br><span class="line">  <span class="keyword">if</span> (block_until_done) &#123;</span><br><span class="line">    <span class="comment">// TODO()</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// All return params are the results of the executable</span></span><br><span class="line">  <span class="keyword">this</span>-&gt;results_ = run_options.return_params;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span> <span class="comment">/*running status*/</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace xrt</span></span><br><span class="line">&#125;  <span class="comment">// namespace oneflow</span></span><br></pre></td></tr></table></figure>
<p>目前为止我们已经完成了一个最简单的运行时executable，这个executable甚至有点类似其他框架中提供的最简单的图执行器（graph
executor）。接下来我们要介绍如何将一个XRT的子图编译成上面的ToyExecutable。</p>
<h2 id="toy-compiler">Toy Compiler</h2>
<p>每个后端引擎都对应一个compiler，当我们希望使用某个后端引擎来执行一个XRT子图时，就需要有一个对应的compiler将该子图编译成后端引擎对应的executable。Compiler通常都非常注重编译产物的执行性能，而性能以外的关切点也导致了不同的技术路线，比如对算法通用性、跨平台有高度关切的TVM和XLA采用了LLVM传统编译器的路线，而对于过分看重性能但硬件平台单一的TensorRT更多的则是采用手工优化和tuning相结合的策略。不过这两种技术路线并不是完全对立的，也是在不断地相互借鉴和融合。</p>
<p>在XRT中，所有这些技术方案都是可以被兼容的，你可以根据实际情况自由切换，你也可以把XRT当成实验场所，实现一个自定义的compiler，并在同一套框架下对比不同compiler、不同技术方案的优劣。</p>
<p>回到本文的主题，我们现在需要实现一个ToyExecutable对应的compiler，我们也把该compiler叫做ToyGraphCompiler。</p>
<p>首先在<code>oneflow_xrt/compiler/toy</code>目录下新建两个文件toy_graph_compiler.h和toy_graph_compiler.cpp。在toy_graph_compiler.h文件中定义类ToyGraphCompiler，ToyGraphCompiler必须继承自类GraphCompiler::Impl，并实现对应的Compile接口。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ToyGraphCompiler</span> : <span class="keyword">public</span> GraphCompiler::Impl &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ToyGraphCompiler</span><span class="params">(<span class="type">const</span> std::string &amp;name)</span></span></span><br><span class="line"><span class="function">      : GraphCompiler::Impl(name) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">ToyGraphCompiler</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">std::shared_ptr&lt;Executable&gt; <span class="title">Compile</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> XrtGraph *graph,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> std::vector&lt;Parameter&gt; &amp;entry_params,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> std::vector&lt;Parameter&gt; &amp;return_params,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> std::vector&lt;InputOutputAlias&gt; &amp;aliases)</span> <span class="keyword">override</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>在toy_graph_compiler.cpp中实现Compile接口，并注册一个新的graph
compiler。在动手实现该接口之前，有必要先解释一下该接口的参数列表，graph表示的是function子图，entry_params表示子图的输入，return_params表示子图的输出，aliases通常在包含模型更新操作时会用到，表明输出和输入是一对别名关系。被alias的输入将生命期延长到了整个子图，并且与对应的输出共享内存，因此也就间接实现了inplace计算的目的。</p>
<p>我们按拓扑顺序遍历子图中的每个节点（或op），依次将节点编译成具体的执行代码，并在合适的位置插入临时buffer。为了方便处理不同类型的op，我们在下面的代码中引入了ToyOpContext和ToyOpKernel的概念。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Register a new graph compiler for TOY engine.</span></span><br><span class="line"><span class="built_in">REGISTER_GRAPH_COMPILER</span>(XrtEngine::TOY, ToyGraphCompiler);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Realize Compile interface.</span></span><br><span class="line"><span class="function">std::shared_ptr&lt;Executable&gt; <span class="title">ToyGraphCompiler::Compile</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> XrtGraph *graph,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::vector&lt;Parameter&gt; &amp;entry_params,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::vector&lt;Parameter&gt; &amp;return_params,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::vector&lt;InputOutputAlias&gt; &amp;aliases)</span> </span>&#123;</span><br><span class="line">  std::vector&lt;Parameter&gt; temp_buffers;</span><br><span class="line">  std::vector&lt;FuncCode&gt; func_codes;</span><br><span class="line">  std::vector&lt;FuncArgumentIndices&gt; func_args;</span><br><span class="line"></span><br><span class="line">  std::unordered_map&lt;std::string, <span class="type">int</span>&gt; indices;</span><br><span class="line">  std::unordered_map&lt;std::string, Parameter&gt; all_params;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> param : entry_params) &#123;</span><br><span class="line">    indices.<span class="built_in">emplace</span>(param.<span class="built_in">name</span>(), indices.<span class="built_in">size</span>());</span><br><span class="line">    all_params[param.<span class="built_in">name</span>()] = param;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> param : return_params) &#123;</span><br><span class="line">    indices.<span class="built_in">emplace</span>(param.<span class="built_in">name</span>(), indices.<span class="built_in">size</span>());</span><br><span class="line">    all_params[param.<span class="built_in">name</span>()] = param;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  algorithm::<span class="built_in">TopologyVisit</span>(*graph, [&amp;](<span class="type">const</span> XrtNode *node) &#123;</span><br><span class="line">    <span class="keyword">if</span> (node-&gt;<span class="built_in">IsNoOpNode</span>()) &#123;</span><br><span class="line">      <span class="comment">// NoOp node is not computation node, so skip it</span></span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ToyOpContext <span class="built_in">op_context</span>(node, all_params);</span><br><span class="line">    <span class="keyword">auto</span> op_kernel = <span class="built_in">BuildToyOpKernel</span>(node-&gt;<span class="built_in">type</span>());</span><br><span class="line">    op_kernel-&gt;<span class="built_in">Compile</span>(&amp;op_context);</span><br><span class="line"></span><br><span class="line">    func_codes.<span class="built_in">push_back</span>(op_context.func_code_);</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> &amp;buffers = op_context.tmp_buffers_;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> it = buffers.<span class="built_in">begin</span>(); it != buffers.<span class="built_in">end</span>(); ++it) &#123;</span><br><span class="line">      all_params[it-&gt;first] = it-&gt;second;</span><br><span class="line">      temp_buffers.<span class="built_in">push_back</span>(it-&gt;second);</span><br><span class="line">      indices.<span class="built_in">emplace</span>(it-&gt;first, indices.<span class="built_in">size</span>());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Finalize argument indices for each function</span></span><br><span class="line">    FuncArgumentIndices arg_indices;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span> &amp;arg : op_context.input_args_) &#123;</span><br><span class="line">      arg_indices.inputs.<span class="built_in">push_back</span>(indices.<span class="built_in">at</span>(arg));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span> &amp;arg : op_context.output_args_) &#123;</span><br><span class="line">      arg_indices.outputs.<span class="built_in">push_back</span>(indices.<span class="built_in">at</span>(arg));</span><br><span class="line">    &#125;</span><br><span class="line">    func_args.<span class="built_in">push_back</span>(std::<span class="built_in">move</span>(arg_indices));</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;ToyExecutable&gt;(<span class="keyword">this</span>-&gt;name_, entry_params.<span class="built_in">size</span>(),</span><br><span class="line">                                          return_params, temp_buffers,</span><br><span class="line">                                          func_codes, func_args);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ToyOpContext临时存储编译需要的元信息和编译结果，为ToyOpKernel提供必要的接口，ToyOpKernel则根据op类型完成单个op的编译过程。上述代码中我们实现了一个将XRT子图编译成ToyExecutable的最简单的graph
compiler，下面我们将以ReLU
op为例，介绍ToyOpContext和ToyOpKernel是如何对op进行编译的。</p>
<h2 id="toy-kernels">Toy Kernels</h2>
<p>我们回过头再仔细研究一下ToyGraphCompiler的Compile实现，ToyOpContext接受两个输入，node和当前所有已经创建过的parameters，经过OpKernel编译后输出函数代码（func_code_）、中间buffer（tmp_buffers_），以及函数代码输入和输出对应的parameter
names。因此在这个例子中，ToyOpContext被设计成如下形式：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ToyOpContext</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">ToyOpContext</span>(<span class="type">const</span> XrtNode *node,</span><br><span class="line">                <span class="type">const</span> std::unordered_map&lt;std::string, Parameter&gt; &amp;all_params)</span><br><span class="line">      : <span class="built_in">node_</span>(node), <span class="built_in">all_params_</span>(all_params) &#123;&#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="type">const</span> XrtNode *node_;</span><br><span class="line">  <span class="type">const</span> std::unordered_map&lt;std::string, Parameter&gt; &amp;all_params_;</span><br><span class="line"></span><br><span class="line">  std::function&lt;<span class="type">void</span>(<span class="type">const</span> std::vector&lt;Parameter&gt;&amp;,</span><br><span class="line">                     <span class="type">const</span> std::vector&lt;Parameter&gt;&amp;)&gt; func_code_;</span><br><span class="line">  std::vector&lt;std::string&gt; input_args_;</span><br><span class="line">  std::vector&lt;std::string&gt; output_args_;</span><br><span class="line">  std::unordered_map&lt;std::string, Parameter&gt; tmp_buffers_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>对于ToyOpKernel，为了处理不同类型的op，我们采用工厂注册模式，并且这种模式还有另一个用处，就是在XRT划分子图时可以用来判断该引擎是否支持某个类型的op。XRT已经将kernel注册接口封装成了一个辅助类OpKernelRegistrar，但同时也要求ToyOpKernel必须继承基类OpKernel。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ToyOpKernel</span> : <span class="keyword">public</span> OpKernel&lt;ToyOpContext&gt; &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Compile</span><span class="params">(ToyOpContext *ctx)</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>使用OpKernelRegistrar定义一个用来注册ToyOpKernel的宏。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> REGISTER_TOY_OP_KERNEL(OpName, KernelType)                  \</span></span><br><span class="line"><span class="meta">  static auto _toy_op_kernel_##OpName##_ __attribute__((unused)) =  \</span></span><br><span class="line"><span class="meta">      OpKernelRegistrar(#OpName)                                    \</span></span><br><span class="line"><span class="meta">          .SetEngine(XrtEngine::TOY)                                \</span></span><br><span class="line"><span class="meta">          .SetDevice(&#123;XrtDevice::GPU_CUDA&#125;)                         \</span></span><br><span class="line"><span class="meta">          .SetFactory([]() -&gt; OpKernelBase * &#123;                      \</span></span><br><span class="line"><span class="meta">                        return new KernelType;                      \</span></span><br><span class="line"><span class="meta">                      &#125;)</span></span><br></pre></td></tr></table></figure>
<p>最后我们实现一个Relu的OpKernel，填充ToyOpContext的func_code_、tmp_buffers_以及输入输出arguments。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ComputeRelu</span><span class="params">(<span class="type">const</span> Parameter &amp;input, <span class="type">const</span> Parameter &amp;output)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//TODO(hjchen2)</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ToyReluOpKernel</span> : <span class="keyword">public</span> ToyOpKernel &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Compile</span><span class="params">(ToyOpContext *ctx)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    ctx-&gt;func_code_ = [](<span class="type">const</span> std::vector&lt;Parameter&gt; &amp;inputs,</span><br><span class="line">                         <span class="type">const</span> std::vector&lt;Parameter&gt; &amp;outputs) &#123;</span><br><span class="line">      <span class="built_in">CHECK_EQ</span>(inputs.<span class="built_in">size</span>(), <span class="number">1</span>);</span><br><span class="line">      <span class="built_in">CHECK_EQ</span>(outputs.<span class="built_in">size</span>(), <span class="number">1</span>);</span><br><span class="line">      <span class="built_in">ComputeRelu</span>(inputs[<span class="number">0</span>], outputs[<span class="number">0</span>]);</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> XrtEdge *edge : ctx-&gt;node_-&gt;<span class="built_in">in_edges</span>()) &#123;</span><br><span class="line">      <span class="type">const</span> <span class="keyword">auto</span> &amp;name = edge-&gt;<span class="built_in">argument</span>().<span class="built_in">name</span>();</span><br><span class="line">      <span class="built_in">CHECK_GT</span>(ctx-&gt;all_params_.<span class="built_in">count</span>(name), <span class="number">0</span>);</span><br><span class="line">      <span class="comment">// TODO(): Filter duplicate input</span></span><br><span class="line">      ctx-&gt;input_args_.<span class="built_in">push_back</span>(name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> XrtEdge *edge : ctx-&gt;node_-&gt;<span class="built_in">out_edges</span>()) &#123;</span><br><span class="line">      <span class="type">const</span> <span class="keyword">auto</span> &amp;name = edge-&gt;<span class="built_in">argument</span>().<span class="built_in">name</span>();</span><br><span class="line">      <span class="comment">// TODO(): Filter duplicate output</span></span><br><span class="line">      ctx-&gt;output_args_.<span class="built_in">push_back</span>(name);</span><br><span class="line">      <span class="keyword">if</span> (ctx-&gt;all_params_.<span class="built_in">count</span>(name) == <span class="number">0</span> &amp;&amp;</span><br><span class="line">          ctx-&gt;tmp_buffers_.<span class="built_in">count</span>(name) == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">auto</span> param = <span class="built_in">CreateParameter</span>(name <span class="comment">/*argument name*/</span>,</span><br><span class="line">                                     edge-&gt;<span class="built_in">argument</span>().<span class="built_in">shape</span>(),</span><br><span class="line">                                     edge-&gt;<span class="built_in">argument</span>().<span class="built_in">data_type</span>());</span><br><span class="line">        ctx-&gt;tmp_buffers_[name] = std::<span class="built_in">move</span>(param);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>最后将ToyReluOpKernel注册到Toy引擎对应的OpKernel工厂下。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_TOY_OP_KERNEL</span>(relu, ToyReluOpKernel)</span><br><span class="line">    .<span class="built_in">EnableTrainPhase</span>()</span><br><span class="line">    .<span class="built_in">Finalize</span>();</span><br></pre></td></tr></table></figure>
<p>EnableTrainPhase表示该op支持训练，OpKernelRegistrar也提供了其他一些接口，比如设置支持的device列表，mutable
variables（inplace更新）和是否是model update op（model update
op会影响子图划分）。</p>
<h2 id="cmake编译">CMake编译</h2>
<p>在CMakeList.txt中添加一个BUILD_TOY的选项，并在oneflow_xrt/CMakeLists.txt中添加如下toy引擎模块的编译代码，</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(BUILD_TOY)</span><br><span class="line">  <span class="keyword">file</span>(GLOB_RECURSE XRT_TOY_SRCS compiler/toy/*.cpp)</span><br><span class="line">  <span class="keyword">add_library</span>(oneflow_xrt_toy <span class="variable">$&#123;XRT_TOY_SRCS&#125;</span>)</span><br><span class="line">  <span class="keyword">add_dependencies</span>(</span><br><span class="line">      oneflow_xrt_toy</span><br><span class="line">      <span class="variable">$&#123;XRT_THIRD_PARTY_LIBRARIES&#125;</span>)</span><br><span class="line">  <span class="keyword">target_link_libraries</span>(</span><br><span class="line">      oneflow_xrt_toy</span><br><span class="line">      oneflow_xrt</span><br><span class="line">      <span class="variable">$&#123;XRT_THIRD_PARTY_LIBRARIES&#125;</span>)</span><br><span class="line">  <span class="keyword">target_include_directories</span>(</span><br><span class="line">      oneflow_xrt_toy PRIVATE <span class="variable">$&#123;ONEFLOW_INCLUDE_DIR&#125;</span>)</span><br><span class="line"><span class="keyword">endif</span>()</span><br></pre></td></tr></table></figure>
<p>之后在oneflow_xrt/python目录中添加导出Python模块的代码toy_stub.cpp，</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pybind11/pybind11.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pybind11/stl.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(_oneflow_xrt_toy_internal, m) &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>并在oneflow_xrt/python/CMakeLists.txt中增加如下代码，</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(BUILD_TOY)</span><br><span class="line">  oneflow_xrt_add_stub(oneflow_xrt_toy toy_stub.cpp)</span><br><span class="line"><span class="keyword">endif</span>()</span><br></pre></td></tr></table></figure>
<h2 id="编译和安装python-wheel包">编译和安装Python wheel包</h2>
<p>修改setup.py文件，新增一个toy
extension的编译，并在build_ext函数中开启BUILD_TOY选项，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">setup_extension(</span><br><span class="line">    <span class="string">&quot;oneflow_xrt_toy&quot;</span>,</span><br><span class="line">    cmake_args=[<span class="string">&quot;-DBUILD_TOY=ON&quot;</span>],</span><br><span class="line">    description=(<span class="string">&quot;oneflow_xrt&#x27;s toy extension&quot;</span>),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>执行命令<code>python3 setup.py install</code>完成wheel包的编译和安装，最后执行如下代码测试添加的toy引擎是否可以正常执行，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> oneflow <span class="keyword">as</span> flow</span><br><span class="line"><span class="keyword">import</span> oneflow_xrt <span class="keyword">as</span> flowrt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ReluGraph</span>(flow.nn.Graph):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="keyword">return</span> flow.nn.functional.relu(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">m = flowrt.XRTModule(ReluGraph(), engine=<span class="string">&quot;toy&quot;</span>)</span><br><span class="line">x = flow.randn(<span class="number">2</span>, <span class="number">3</span>, device=<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(m(x))</span><br></pre></td></tr></table></figure>

      
    </div>
      
      <footer>
        
  
  <div class="categories">
    <a href="/categories/XRT/">XRT</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/XRT/">XRT</a>, <a href="/tags/Compiler/">Compiler</a>, <a href="/tags/TensorFlow-XLA/">TensorFlow XLA</a>, <a href="/tags/TensorRT/">TensorRT</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
      </footer>
  </div>
</article>


<section id="comment">
  
</section>




  
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:hjchen2.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Recent Posts</h3>
  <ul class="entry">
    
      <li>
        <a href="/2023/02/24/IREE编译流程6/">IREE编译流程解析(六)</a>
      </li>
    
      <li>
        <a href="/2023/02/13/IREE编译流程5/">IREE编译流程解析(五)</a>
      </li>
    
      <li>
        <a href="/2023/01/04/IREE编译流程4/">IREE编译流程解析(四)</a>
      </li>
    
      <li>
        <a href="/2023/01/04/IREE编译流程3/">IREE编译流程解析(三)</a>
      </li>
    
      <li>
        <a href="/2023/01/04/IREE编译流程2/">IREE编译流程解析(二)</a>
      </li>
    
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">Categories</h3>
  <ul class="entry">
  
    <li><a href="/categories/DL-Compiler/">DL Compiler</a><small>8</small></li>
  
    <li><a href="/categories/Daily/">Daily</a><small>1</small></li>
  
    <li><a href="/categories/ML-framework/">ML framework</a><small>2</small></li>
  
    <li><a href="/categories/XRT/">XRT</a><small>1</small></li>
  
    <li><a href="/categories/code/">code</a><small>1</small></li>
  
    <li><a href="/categories/deep-learning/">deep learning</a><small>1</small></li>
  
    <li><a href="/categories/graph-optimization-图优化/">graph optimization, 图优化</a><small>1</small></li>
  
    <li><a href="/categories/kaldi-decision-tree-决策树/">kaldi, decision tree, 决策树</a><small>1</small></li>
  
    <li><a href="/categories/low-bitwidth/">low bitwidth</a><small>1</small></li>
  
    <li><a href="/categories/model-compression/">model compression</a><small>1</small></li>
  
    <li><a href="/categories/neural-machine-translation/">neural machine translation</a><small>1</small></li>
  
    <li><a href="/categories/reinforcement-learning/">reinforcement learning</a><small>3</small></li>
  
    <li><a href="/categories/tvm-knowledge/">tvm knowledge</a><small>1</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2023 Dou Jiang
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



</body>
</html>

